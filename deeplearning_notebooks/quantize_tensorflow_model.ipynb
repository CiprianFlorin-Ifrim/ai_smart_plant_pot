{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72eaa78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/454yhlzx6hd15j7rjv4th0lw0000gn/T/ipykernel_90169/4123656545.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------JUPYTER NOTEBOOK SETTINGS-------------------------------------------------------------------------------------\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  \n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd8d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cf27daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training data\n",
    "x_test, y_test = load('/Users/ciprian/Desktop/Projects/Smart Plant Pot/Software/ai_smart_plant_pot/Python/saved_data/data/adversarial-training_medium-masked_data/test_data.joblib')\n",
    "x_test = np.array(x_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196e35b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ry/454yhlzx6hd15j7rjv4th0lw0000gn/T/tmpgoe7soew/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ry/454yhlzx6hd15j7rjv4th0lw0000gn/T/tmpgoe7soew/assets\n",
      "/Users/ciprian/Documents/anaconda/anaconda3/envs/tf_2.1/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:947: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-05-22 05:03:51.827593: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-22 05:03:51.827610: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-22 05:03:51.827745: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/ry/454yhlzx6hd15j7rjv4th0lw0000gn/T/tmpgoe7soew\n",
      "2024-05-22 05:03:51.840809: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-22 05:03:51.840825: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/ry/454yhlzx6hd15j7rjv4th0lw0000gn/T/tmpgoe7soew\n",
      "2024-05-22 05:03:51.874768: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-22 05:03:52.299432: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/ry/454yhlzx6hd15j7rjv4th0lw0000gn/T/tmpgoe7soew\n",
      "2024-05-22 05:03:52.415067: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 587321 microseconds.\n",
      "2024-05-22 05:03:52.912100: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2178] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexFusedBatchNormV3\n",
      "Details:\n",
      "\ttf.FusedBatchNormV3(tensor<?x112x112x16xf32>, tensor<16xf32>, tensor<16xf32>, tensor<16xf32>, tensor<16xf32>) -> (tensor<?x112x112x16xf32>, tensor<16xf32>, tensor<16xf32>, tensor<16xf32>, tensor<16xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x112x112x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>) -> (tensor<?x112x112x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x112x112x96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>) -> (tensor<?x112x112x96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x14x14x192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<192xf32>) -> (tensor<?x14x14x192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x14x14x384xf32>, tensor<384xf32>, tensor<384xf32>, tensor<384xf32>, tensor<384xf32>) -> (tensor<?x14x14x384xf32>, tensor<384xf32>, tensor<384xf32>, tensor<384xf32>, tensor<384xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x14x14x576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<576xf32>) -> (tensor<?x14x14x576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x14x14x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> (tensor<?x14x14x64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x14x14x96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>) -> (tensor<?x14x14x96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x28x28x144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<144xf32>) -> (tensor<?x28x28x144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x28x28x192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<192xf32>) -> (tensor<?x28x28x192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<192xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x28x28x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>) -> (tensor<?x28x28x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x56x56x144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<144xf32>) -> (tensor<?x56x56x144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<144xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x56x56x24xf32>, tensor<24xf32>, tensor<24xf32>, tensor<24xf32>, tensor<24xf32>) -> (tensor<?x56x56x24xf32>, tensor<24xf32>, tensor<24xf32>, tensor<24xf32>, tensor<24xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x56x56x96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>) -> (tensor<?x56x56x96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<96xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x7x7x1280xf32>, tensor<1280xf32>, tensor<1280xf32>, tensor<1280xf32>, tensor<1280xf32>) -> (tensor<?x7x7x1280xf32>, tensor<1280xf32>, tensor<1280xf32>, tensor<1280xf32>, tensor<1280xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x7x7x160xf32>, tensor<160xf32>, tensor<160xf32>, tensor<160xf32>, tensor<160xf32>) -> (tensor<?x7x7x160xf32>, tensor<160xf32>, tensor<160xf32>, tensor<160xf32>, tensor<160xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x7x7x320xf32>, tensor<320xf32>, tensor<320xf32>, tensor<320xf32>, tensor<320xf32>) -> (tensor<?x7x7x320xf32>, tensor<320xf32>, tensor<320xf32>, tensor<320xf32>, tensor<320xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x7x7x576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<576xf32>) -> (tensor<?x7x7x576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<576xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "\ttf.FusedBatchNormV3(tensor<?x7x7x960xf32>, tensor<960xf32>, tensor<960xf32>, tensor<960xf32>, tensor<960xf32>) -> (tensor<?x7x7x960xf32>, tensor<960xf32>, tensor<960xf32>, tensor<960xf32>, tensor<960xf32>, tensor<*xf32>) : {data_format = \"NHWC\", device = \"\", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e-03 : f32, is_training = true}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "# Define GradientReversalLayer for adversarial models\n",
    "class GradientReversalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, lambda_, **kwargs):\n",
    "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def call(self, x):\n",
    "        def grad(dy):\n",
    "            return -self.lambda_ * dy\n",
    "        return x, grad\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"lambda_\": self.lambda_\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "# Custom objects dictionary\n",
    "custom_objects = {\"GradientReversalLayer\": GradientReversalLayer}\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"saved_data/models/adversarial-training_medium-masked_mobilenetv2_fine-tuning_v3/adversarial-training_medium-masked_mobilenetv2_fine-tuning.keras\", custom_objects=custom_objects)\n",
    "\n",
    "# Convert the model to TensorFlow Lite format with full integer quantization and TF Select\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Provide the representative dataset\n",
    "def representative_dataset():\n",
    "    for i in range(100):  # Adjust the number of samples as needed\n",
    "        data = x_test[i:i+1]  # Yield one sample at a time\n",
    "        yield [tf.convert_to_tensor(data, dtype=tf.float32)]\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# Specify the target specification to use only integer operations\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.inference_input_type = tf.uint8  # or tf.int8\n",
    "converter.inference_output_type = tf.uint8  # or tf.int8\n",
    "\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('quantized_adversarial_model_int8.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2.14",
   "language": "python",
   "name": "tf-2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
