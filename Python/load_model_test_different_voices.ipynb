{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------JUPYTER NOTEBOOK SETTINGS-------------------------------------------------------------------------------------\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Layer, Input, Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb01dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for Adversarial Trained Models\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class GradientReversalLayer(Layer):\n",
    "    def __init__(self, lambda_=1.0, **kwargs):\n",
    "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def call(self, x):\n",
    "        def grad(dy):\n",
    "            return -self.lambda_ * dy\n",
    "        return x, grad\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"lambda_\": self.lambda_})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf0ce5",
   "metadata": {},
   "source": [
    "### Standalone File Probabilities Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5533b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Samples\n",
    "def process_wav_file(wav_file_path, max_length=332):\n",
    "    # Load the WAV file\n",
    "    signal, sr = librosa.load(wav_file_path, sr=16000)  # Ensure sample rate is 16000 Hz\n",
    "    # Compute MFCC features\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13, n_fft=256, hop_length=160, n_mels=32, fmin=0, fmax=8000)\n",
    "    # Calculate padding width\n",
    "    pad_width = max_length - mfccs.shape[1]\n",
    "    if pad_width > 0:  # Apply padding if needed\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfccs\n",
    "\n",
    "def predict_wav_file(wav_file_path, model, label_encoder):\n",
    "    # Process the WAV file to get padded MFCCs\n",
    "    mfccs_padded = process_wav_file(wav_file_path)\n",
    "\n",
    "    # Reshape the input to fit the model by adding a batch dimension\n",
    "    mfccs_padded = mfccs_padded[np.newaxis, ...]  # Add batch dimension, reshaping (13, 332) to (1, 13, 332)\n",
    "\n",
    "    # Perform prediction using the model to get softmax outputs\n",
    "    softmax_output = model.predict(mfccs_padded)[0]  # [0] to get the first (and only) batch item\n",
    "    \n",
    "    # Create a DataFrame to hold the probabilities associated with each label\n",
    "    labels = label_encoder.classes_  # Assuming label_encoder has all labels\n",
    "    probabilities_df = pd.DataFrame(softmax_output, index=labels, columns=['Probability'])\n",
    "\n",
    "    return probabilities_df\n",
    "\n",
    "model = model = load_model('saved_data/models/non-masked_custom_cnn/custom-cnn_final_model.keras')  # Load pre-trained model\n",
    "\n",
    "all_labels = ['battery', 'description', 'environment', 'greeting', 'health', 'noise', 'noise', 'nutrition', 'silence', 'sun', 'water']  \n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Path to the WAV file \n",
    "wav_file_path = '/Users/ciprian/Desktop/Projects/Smart Plant Pot/Audio/Voice Recognition/_testing_samples_bianca/are you hot?.mp3'  \n",
    "\n",
    "# Get the prediction DataFrame\n",
    "probabilities_df = predict_wav_file(wav_file_path, model, label_encoder)\n",
    "\n",
    "# Find the highest probability\n",
    "max_label = probabilities_df['Probability'].idxmax()\n",
    "highest_probability = probabilities_df['Probability'].max()\n",
    "print(f\"The highest probability is {highest_probability}, associated with label '{max_label}'\")\n",
    "\n",
    "probabilities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604f416",
   "metadata": {},
   "source": [
    "### Multi Sub-directory Processing with Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a7adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(file_path, max_length=332):\n",
    "    # Load the audio file with librosa, handle both mp3 and wav formats\n",
    "    signal, sr = librosa.load(file_path, sr=16000)\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13, n_fft=256, hop_length=160, n_mels=32, fmin=0, fmax=8000)\n",
    "    pad_width = max_length - mfccs.shape[1]\n",
    "    if pad_width > 0:\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfccs\n",
    "\n",
    "def predict_audio_file(model, label_encoder, mfccs_padded):\n",
    "    mfccs_padded = mfccs_padded[np.newaxis, ...]  # Add batch dimension\n",
    "    softmax_output = model.predict(mfccs_padded)[0]  # Get the first batch item\n",
    "    labels = label_encoder.classes_\n",
    "    # Reshape the output if necessary\n",
    "    if softmax_output.shape[0] != len(labels):\n",
    "        softmax_output = softmax_output.reshape(-1, len(labels))\n",
    "    probabilities_df = pd.DataFrame(softmax_output.T, index=labels, columns=['Probability'])\n",
    "    return probabilities_df\n",
    "\n",
    "def process_directory(directory, model, label_encoder):\n",
    "    results = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for sub_dir in dirs:\n",
    "            correct_predictions = 0\n",
    "            total_files = 0\n",
    "            sub_dir_path = os.path.join(root, sub_dir)\n",
    "            print(f\"Processing subdirectory: {sub_dir_path}\")\n",
    "            for file in tqdm(os.listdir(sub_dir_path), desc=f\"Analyzing {sub_dir}\"):\n",
    "                if file.endswith(('.wav', '.mp3')):\n",
    "                    file_path = os.path.join(sub_dir_path, file)\n",
    "                    label_from_filename = file.split('_')[0]  # Assuming the label is the first word in the filename\n",
    "                    mfccs_padded = process_audio_file(file_path)\n",
    "                    probabilities_df = predict_audio_file(model, label_encoder, mfccs_padded)\n",
    "                    predicted_label = probabilities_df['Probability'].idxmax()\n",
    "                    highest_probability = probabilities_df['Probability'].max()\n",
    "                    results.append([sub_dir, file, label_from_filename, predicted_label, highest_probability])\n",
    "                    if predicted_label == label_from_filename:\n",
    "                        correct_predictions += 1\n",
    "                    total_files += 1\n",
    "            \n",
    "            accuracy = (correct_predictions / total_files) * 100 if total_files > 0 else 0\n",
    "            results.append([sub_dir, \"Accuracy\", \"\", \"\", accuracy])\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['Subdirectory', 'Filename', 'Correct Label', 'Predicted Label', 'Probability'])\n",
    "    return results_df\n",
    "\n",
    "# Custom objects dictionary\n",
    "custom_objects = {\"GradientReversalLayer\": GradientReversalLayer}\n",
    "\n",
    "# Load the pre-trained model and label encoder\n",
    "model = load_model('saved_data/adversarial-training_custom-cnn_final_model.keras', custom_objects=custom_objects)\n",
    "all_labels = ['battery', 'description', 'environment', 'greeting', 'health', 'noise', 'nutrition', 'silence', 'sun', 'water']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Specify the directory containing subdirectories with audio files\n",
    "directory = '/Users/ciprian/Desktop/Projects/Smart Plant Pot/Audio/Voice Recognition/Testing Samples'\n",
    "\n",
    "# Process the directory and get predictions along with accuracy\n",
    "predictions_df = process_directory(directory, model, label_encoder)\n",
    "predictions_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
