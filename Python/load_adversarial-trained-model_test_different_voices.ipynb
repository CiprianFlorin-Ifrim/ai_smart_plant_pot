{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------JUPYTER NOTEBOOK SETTINGS-------------------------------------------------------------------------------------\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  \n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Layer, Input, Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping \n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='keras.src.saving.saving_lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea67e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up mixed precision policy\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604f416",
   "metadata": {},
   "source": [
    "### Multi Sub-directory Processing with Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a7adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(file_path, max_length=332):\n",
    "    # Load the audio file with librosa, handle both mp3 and wav formats\n",
    "    signal, sr = librosa.load(file_path, sr=16000)\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13, n_fft=256, hop_length=160, n_mels=32, fmin=0, fmax=8000)\n",
    "    pad_width = max_length - mfccs.shape[1]\n",
    "    if pad_width > 0:\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfccs\n",
    "\n",
    "def predict_audio_file(model, label_encoder, mfccs_padded):\n",
    "    mfccs_padded = mfccs_padded[np.newaxis, ...]  # Add batch dimension\n",
    "    softmax_output = model.predict(mfccs_padded)[0]  # Get the first batch item\n",
    "    labels = label_encoder.classes_\n",
    "    probabilities_df = pd.DataFrame(softmax_output, index=labels, columns=['Probability'])\n",
    "    return probabilities_df\n",
    "\n",
    "def process_directory(directory, model, label_encoder):\n",
    "    results = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for sub_dir in dirs:\n",
    "            correct_predictions = 0\n",
    "            total_files = 0\n",
    "            sub_dir_path = os.path.join(root, sub_dir)\n",
    "            print(f\"Processing subdirectory: {sub_dir_path}\")\n",
    "            for file in tqdm(os.listdir(sub_dir_path), desc=f\"Analyzing {sub_dir}\"):\n",
    "                if file.endswith(('.wav', '.mp3')):\n",
    "                    file_path = os.path.join(sub_dir_path, file)\n",
    "                    label_from_filename = file.split('_')[0]  # Assuming the label is the first word in the filename\n",
    "                    mfccs_padded = process_audio_file(file_path)\n",
    "                    probabilities_df = predict_audio_file(model, label_encoder, mfccs_padded)\n",
    "                    predicted_label = probabilities_df['Probability'].idxmax()\n",
    "                    highest_probability = probabilities_df['Probability'].max()\n",
    "                    results.append([sub_dir, file, label_from_filename, predicted_label, highest_probability])\n",
    "                    if predicted_label == label_from_filename:\n",
    "                        correct_predictions += 1\n",
    "                    total_files += 1\n",
    "            \n",
    "            accuracy = (correct_predictions / total_files) * 100 if total_files > 0 else 0\n",
    "            results.append([sub_dir, \"Accuracy\", \"\", \"\", accuracy])\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['Subdirectory', 'Filename', 'Correct Label', 'Predicted Label', 'Probability'])\n",
    "    return results_df\n",
    "\n",
    "# Load the pre-trained model and label encoder\n",
    "model = load_model('saved_data/models/non-masked_mobilenetv3-finetuned/mobilenetv3small_finetuned_model.keras')\n",
    "all_labels = ['battery', 'description', 'environment', 'greeting', 'health', 'noise', 'nutrition', 'silence', 'sun', 'water']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Specify the directory containing subdirectories with audio files\n",
    "directory = '/Users/ciprian/Desktop/Projects/Smart Plant Pot/Audio/Voice Recognition/Testing Samples'\n",
    "\n",
    "# Process the directory and get predictions along with accuracy\n",
    "predictions_df = process_directory(directory, model, label_encoder)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GradientReversalLayer for adversarial models (if any exist)\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class GradientReversalLayer(Layer):\n",
    "    def __init__(self, lambda_=1.0, **kwargs):\n",
    "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def call(self, x):\n",
    "        def grad(dy):\n",
    "            return -self.lambda_ * dy\n",
    "        return x, grad\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"lambda_\": self.lambda_})\n",
    "        return config\n",
    "\n",
    "def process_audio_file(file_path, max_length=332):\n",
    "    # Load the audio file with librosa, handle both mp3 and wav formats\n",
    "    signal, sr = librosa.load(file_path, sr=16000)\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13, n_fft=256, hop_length=160, n_mels=32, fmin=0, fmax=8000)\n",
    "    pad_width = max_length - mfccs.shape[1]\n",
    "    if pad_width > 0:\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfccs\n",
    "\n",
    "def evaluate_model_directory(model_path, test_directory, label_encoder):\n",
    "    # Function to evaluate a model using audio files in the test directory\n",
    "    try:\n",
    "        custom_objects = {\"GradientReversalLayer\": GradientReversalLayer}\n",
    "        model = load_model(model_path, custom_objects=custom_objects)\n",
    "    except:\n",
    "        model = load_model(model_path)  # For models without adversarial training\n",
    "    \n",
    "    results = []\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    for root, _, files in os.walk(test_directory):\n",
    "        for file in tqdm(files, desc=f\"Processing {os.path.basename(model_path)}\"):\n",
    "            if file.endswith(('.wav', '.mp3')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                label_from_filename = file.split('_')[0]  # Assuming the label is the first word in the filename\n",
    "                mfccs_padded = process_audio_file(file_path)\n",
    "                mfccs_padded = mfccs_padded[np.newaxis, ...]  # Add batch dimension\n",
    "                \n",
    "                predictions = model.predict(mfccs_padded)\n",
    "                \n",
    "                if isinstance(predictions, list):  # Adversarial model\n",
    "                    y_pred_task = predictions[0]\n",
    "                else:  # Non-adversarial model\n",
    "                    y_pred_task = predictions\n",
    "                \n",
    "                predicted_label = label_encoder.inverse_transform(np.argmax(y_pred_task, axis=1))[0]\n",
    "                \n",
    "                y_true.append(label_from_filename)\n",
    "                y_pred.append(predicted_label)\n",
    "                \n",
    "                results.append([file, label_from_filename, predicted_label])\n",
    "    \n",
    "    command_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    command_precision = precision_score(y_true, y_pred, average='weighted', zero_division=0) * 100\n",
    "    command_recall = recall_score(y_true, y_pred, average='weighted', zero_division=0) * 100\n",
    "    command_f1 = f1_score(y_true, y_pred, average='weighted') * 100\n",
    "    \n",
    "    return results, command_accuracy, command_precision, command_recall, command_f1\n",
    "\n",
    "# Set the path to the models directory and the test data directory\n",
    "models_directory = 'saved_data/models'\n",
    "test_directory = '/Users/ciprian/Desktop/Projects/Smart Plant Pot/Audio/Voice Recognition/Testing Samples'\n",
    "\n",
    "# Label encoder setup\n",
    "all_labels = ['battery', 'description', 'environment', 'greeting', 'health', 'noise', 'nutrition', 'silence', 'sun', 'water']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Iterate through subdirectories in the test directory and evaluate models\n",
    "overall_results = []\n",
    "subdir_results = {}\n",
    "\n",
    "for subdir, _, _ in os.walk(test_directory):\n",
    "    subdir_name = os.path.basename(subdir)\n",
    "    if subdir_name not in subdir_results:\n",
    "        subdir_results[subdir_name] = []\n",
    "    \n",
    "    for model_subdir, _, model_files in os.walk(models_directory):\n",
    "        for model_file in model_files:\n",
    "            if model_file.endswith('.keras'):\n",
    "                model_path = os.path.join(model_subdir, model_file)\n",
    "                model_folder = os.path.basename(model_subdir)\n",
    "                \n",
    "                model_results, command_accuracy, command_precision, command_recall, command_f1 = evaluate_model_directory(model_path, subdir, label_encoder)\n",
    "                \n",
    "                result_entry = {\n",
    "                    'Model': model_folder,\n",
    "                    'Command Accuracy (%)': f\"{command_accuracy:.2f}\",\n",
    "                    'Command Precision (%)': f\"{command_precision:.2f}\",\n",
    "                    'Command Recall (%)': f\"{command_recall:.2f}\",\n",
    "                    'Command F1 (%)': f\"{command_f1:.2f}\"\n",
    "                }\n",
    "                subdir_results[subdir_name].append(result_entry)\n",
    "                overall_results.append(result_entry)\n",
    "\n",
    "# Display performance DataFrames for each subdirectory\n",
    "for subdir_name, results in subdir_results.items():\n",
    "    if results:  # Only display if there are results\n",
    "        print(f\"Performance for {subdir_name}:\")\n",
    "        subdir_df = pd.DataFrame(results)\n",
    "        ipd.display(ipd.HTML(subdir_df.to_html(index=False)))\n",
    "\n",
    "# Create a summary DataFrame with the best model for each subdirectory\n",
    "summary_results = []\n",
    "\n",
    "for subdir_name, results in subdir_results.items():\n",
    "    subdir_df = pd.DataFrame(results)\n",
    "    if not subdir_df.empty and 'Command Accuracy (%)' in subdir_df.columns and 'Command F1 (%)' in subdir_df.columns:\n",
    "        best_accuracy_model = subdir_df.loc[subdir_df['Command Accuracy (%)'].astype(float).idxmax()]\n",
    "        best_f1_model = subdir_df.loc[subdir_df['Command F1 (%)'].astype(float).idxmax()]\n",
    "        summary_results.append({\n",
    "            'Subdirectory': subdir_name,\n",
    "            'Best Accuracy Model': best_accuracy_model['Model'],\n",
    "            'Best Accuracy (%)': best_accuracy_model['Command Accuracy (%)'],\n",
    "            'Best F1 Model': best_f1_model['Model'],\n",
    "            'Best F1 Score (%)': best_f1_model['Command F1 (%)']\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "\n",
    "# Display the final summary DataFrame\n",
    "print(\"Overall Performance Summary:\")\n",
    "ipd.display(ipd.HTML(summary_df.to_html(index=False)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
