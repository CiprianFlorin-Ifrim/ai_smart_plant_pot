{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc878b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------JUPYTER NOTEBOOK SETTINGS-------------------------------------------------------------------------------------\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  \n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4818c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import json\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import randint, uniform\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a89f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sr=16000, n_mfcc=13, n_fft=512, hop_length=320, n_mels=32, fmin=80, fmax=8000, window_size=None):\n",
    "        self.sr = sr\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.window_size is None:\n",
    "            self.window_size = self._calculate_max_window_size(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        features = Parallel(n_jobs=-1, backend='threading')(delayed(self._extract_mfcc)(wav_file) for wav_file in tqdm(X, desc=\"Extracting MFCC features\"))\n",
    "        return np.array(features)\n",
    "\n",
    "    def _extract_mfcc(self, wav_file):\n",
    "        signal, sr = librosa.load(wav_file, sr=self.sr)\n",
    "        mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=self.n_mfcc, n_fft=self.n_fft,\n",
    "                                     hop_length=self.hop_length, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax)\n",
    "        if mfccs.shape[1] < self.window_size:\n",
    "            pad_width = self.window_size - mfccs.shape[1]\n",
    "            pad_value = mfccs.mean()\n",
    "            mfccs = np.pad(mfccs, ((0, 0), (0, pad_width)), mode='constant', constant_values=pad_value)\n",
    "        else:\n",
    "            mfccs = mfccs[:, :self.window_size]\n",
    "        return mfccs.flatten()\n",
    "\n",
    "    def _calculate_max_window_size(self, files):\n",
    "        max_window_size = 0\n",
    "        for wav_file in tqdm(files, desc=\"Calculating max window size\"):\n",
    "            signal, _ = librosa.load(wav_file, sr=self.sr)\n",
    "            duration = len(signal) / self.sr\n",
    "            window_size = int(np.floor((duration * self.sr - self.n_fft) / self.hop_length) + 1)\n",
    "            if window_size > max_window_size:\n",
    "                max_window_size = window_size\n",
    "        return max_window_size\n",
    "\n",
    "def load_files_and_labels(root_dir):\n",
    "    files = []\n",
    "    labels = []\n",
    "    \n",
    "    for subdir, _, subfiles in os.walk(root_dir):\n",
    "        for file in subfiles:\n",
    "            if file.endswith('.wav'):\n",
    "                files.append(os.path.join(subdir, file))\n",
    "                labels.append(os.path.basename(subdir))  # Use the final subdirectory as the label\n",
    "    \n",
    "    return files, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = '/Users/ciprian/Desktop/Projects/Smart Plant Pot/Audio/Voice Recognition/Prototype 4'  \n",
    "\n",
    "    # Load all files and labels from all subdirectories\n",
    "    files, labels = load_files_and_labels(root_dir)\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    # Subsample data for parameter tuning\n",
    "    subsample_size = 10000  # Adjust based on available computational resources\n",
    "    subsample_indices = np.random.choice(len(files), size=subsample_size, replace=False)\n",
    "    files_subsample = [files[i] for i in subsample_indices]\n",
    "    labels_subsample = [labels_encoded[i] for i in subsample_indices]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(files_subsample, labels_subsample, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('mfcc', MFCCFeatureExtractor()),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "    \n",
    "    # Define the parameter distributions for RandomizedSearchCV\n",
    "    param_dist = {\n",
    "        'mfcc__sr': [16000],\n",
    "        'mfcc__n_mfcc': randint(10, 30),\n",
    "        'mfcc__n_fft': randint(128, 512),\n",
    "        'mfcc__hop_length': randint(80, 320),\n",
    "        'mfcc__n_mels': randint(20, 50),\n",
    "        'mfcc__fmin': uniform(0, 100),  # Search fmin in the range 0 to 100 Hz\n",
    "        'mfcc__fmax': uniform(4000, 8000)\n",
    "    }\n",
    "    \n",
    "    # Perform random search\n",
    "    random_search = RandomizedSearchCV(pipeline, param_dist, n_iter=50, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best parameters from the random search\n",
    "    best_params_random = random_search.best_params_\n",
    "    print(f\"Best Parameters from Random Search: {best_params_random}\")\n",
    "\n",
    "    # Define a narrower grid based on the random search results for GridSearchCV\n",
    "    param_grid = {\n",
    "        'mfcc__sr': [16000],\n",
    "        'mfcc__n_mfcc': [best_params_random['mfcc__n_mfcc']-2, best_params_random['mfcc__n_mfcc'], best_params_random['mfcc__n_mfcc']+2],\n",
    "        'mfcc__n_fft': [best_params_random['mfcc__n_fft']-64, best_params_random['mfcc__n_fft'], best_params_random['mfcc__n_fft']+64],\n",
    "        'mfcc__hop_length': [best_params_random['mfcc__hop_length']-40, best_params_random['mfcc__hop_length'], best_params_random['mfcc__hop_length']+40],\n",
    "        'mfcc__n_mels': [best_params_random['mfcc__n_mels']-5, best_params_random['mfcc__n_mels'], best_params_random['mfcc__n_mels']+5],\n",
    "        'mfcc__fmin': [max(0, best_params_random['mfcc__fmin']-10), best_params_random['mfcc__fmin'], best_params_random['mfcc__fmin']+10],\n",
    "        'mfcc__fmax': [best_params_random['mfcc__fmax']-1000, best_params_random['mfcc__fmax'], best_params_random['mfcc__fmax']+1000]\n",
    "    }\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best parameters and score\n",
    "    best_params_grid = grid_search.best_params_\n",
    "    best_score_grid = grid_search.best_score_\n",
    "    \n",
    "    print(f\"Best Parameters from Grid Search: {best_params_grid}\")\n",
    "    print(f\"Best Cross-Validation Score from Grid Search: {best_score_grid}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_score = grid_search.score(X_test, y_test)\n",
    "    print(f\"Test Set Score: {test_score}\")\n",
    "\n",
    "    # Calculate the best window size based on the best parameters\n",
    "    mfcc_extractor = MFCCFeatureExtractor(\n",
    "        sr=best_params_grid['mfcc__sr'],\n",
    "        n_mfcc=best_params_grid['mfcc__n_mfcc'],\n",
    "        n_fft=best_params_grid['mfcc__n_fft'],\n",
    "        hop_length=best_params_grid['mfcc__hop_length'],\n",
    "        n_mels=best_params_grid['mfcc__n_mels'],\n",
    "        fmin=best_params_grid['mfcc__fmin'],\n",
    "        fmax=best_params_grid['mfcc__fmax']\n",
    "    )\n",
    "    mfcc_extractor.fit(X_train)\n",
    "    best_window_size = mfcc_extractor.window_size\n",
    "    print(f\"Best Window Size: {best_window_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae35da",
   "metadata": {},
   "source": [
    "### Save the best parameters and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28812b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the values to a JSON file\n",
    "results = {\n",
    "    'best_params_grid': best_params_grid,\n",
    "    'best_score_grid': best_score_grid,\n",
    "    'test_score': test_score,\n",
    "    'best_window_size': best_window_size\n",
    "}\n",
    "\n",
    "with open('saved_data/best_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1f494",
   "metadata": {},
   "source": [
    "### Test specific upper frequency levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc81547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the two fmax and n_mfcc values to compare\n",
    "fmax_values = [4567.87, 4568, 8000]\n",
    "n_mfcc_values = [13, 22]\n",
    "\n",
    "# Prepare data\n",
    "root_dir = '/Users/ciprian/Desktop/Projects/Smart Plant Pot/Audio/Voice Recognition/Prototype 4'  \n",
    "files, labels = load_files_and_labels(root_dir)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Subsample data for the experiment\n",
    "subsample_size = 10000\n",
    "subsample_indices = np.random.choice(len(files), size=subsample_size, replace=False)\n",
    "files_subsample = [files[i] for i in subsample_indices]\n",
    "labels_subsample = [labels_encoded[i] for i in subsample_indices]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(files_subsample, labels_subsample, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to create pipeline with given fmax and n_mfcc\n",
    "def create_pipeline(fmax, n_mfcc):\n",
    "    return Pipeline([\n",
    "        ('mfcc', MFCCFeatureExtractor(fmax=fmax, sr=16000, n_mfcc=n_mfcc, n_fft=404, hop_length=119, n_mels=35, fmin=0)),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "# Compare performance for different fmax and n_mfcc values\n",
    "for fmax in fmax_values:\n",
    "    for n_mfcc in n_mfcc_values:\n",
    "        pipeline = create_pipeline(fmax, n_mfcc)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy with fmax={fmax}, n_mfcc={n_mfcc}: {accuracy}\")\n",
    "\n",
    "# Output the window size for each fmax and n_mfcc value\n",
    "for fmax in fmax_values:\n",
    "    for n_mfcc in n_mfcc_values:\n",
    "        mfcc_extractor = MFCCFeatureExtractor(fmax=fmax, sr=16000, n_mfcc=n_mfcc, n_fft=404, hop_length=119, n_mels=35, fmin=0)\n",
    "        mfcc_extractor.fit(X_train)\n",
    "        best_window_size = mfcc_extractor.window_size\n",
    "        print(f\"Best Window Size with fmax={fmax}, n_mfcc={n_mfcc}: {best_window_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d55cfe",
   "metadata": {},
   "source": [
    "### Extract features from wav samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e34904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCFeatureExtractor:\n",
    "    def __init__(self, sr=16000, n_mfcc=13, n_fft=256, hop_length=160, n_mels=32, fmin=0, fmax=8000):\n",
    "        self.sr = sr\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "\n",
    "    def extract_features_from_file(self, wav_file, window_size):\n",
    "        try:\n",
    "            # Load the audio file\n",
    "            signal, sr = librosa.load(wav_file, sr=self.sr)\n",
    "            # Extract MFCC features\n",
    "            mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=self.n_mfcc, n_fft=self.n_fft, hop_length=self.hop_length, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax)\n",
    "            # Padding\n",
    "            if mfccs.shape[1] < window_size:\n",
    "                pad_width = window_size - mfccs.shape[1]\n",
    "                mfccs = np.pad(mfccs, ((0, 0), (0, pad_width)), mode='mean')\n",
    "            else:\n",
    "                mfccs = mfccs[:, :window_size]\n",
    "            return mfccs\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {wav_file}: {e}\")\n",
    "            return None\n",
    "\n",
    "def process_directory(root_dir, window_size, mfcc_extractor, pbar):\n",
    "    mfcc_features = []\n",
    "    labels = []\n",
    "    gender_labels = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                wav_file = os.path.join(subdir, file)\n",
    "                gender_label = os.path.basename(os.path.dirname(os.path.dirname(wav_file)))\n",
    "                audio_label = os.path.basename(os.path.dirname(wav_file))\n",
    "\n",
    "                mfcc = mfcc_extractor.extract_features_from_file(wav_file, window_size)\n",
    "                if mfcc is not None:\n",
    "                    mfcc_features.append(mfcc)\n",
    "                    labels.append(audio_label)\n",
    "                    gender_labels.append(gender_label)\n",
    "            pbar.update(1)  # Update the progress bar\n",
    "\n",
    "    return np.array(mfcc_features), np.array(labels), np.array(gender_labels)\n",
    "\n",
    "def main(root_dir, window_size, mfcc_extractor):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        subdirs = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "\n",
    "        total_files = sum(len(files) for _, _, files in os.walk(root_dir) if any(file.endswith('.wav') for file in files))\n",
    "        with tqdm(total=total_files, desc=\"Processing files\") as pbar:\n",
    "            futures = []\n",
    "            for subdir in subdirs:\n",
    "                futures.append(executor.submit(process_directory, subdir, window_size, mfcc_extractor, pbar))\n",
    "\n",
    "            mfcc_features = []\n",
    "            labels = []\n",
    "            gender_labels = []\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    mfccs, lbls, g_lbls = result\n",
    "                    mfcc_features.extend(mfccs)\n",
    "                    labels.extend(lbls)\n",
    "                    gender_labels.extend(g_lbls)\n",
    "\n",
    "    return np.array(mfcc_features), np.array(labels), np.array(gender_labels)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = '/Users/ciprian/Desktop/Projects/Smart Plant Pot/Audio/Voice Recognition/Prototype 4' \n",
    "\n",
    "    with open('saved_data/best_results.json', 'r') as f:\n",
    "        loaded_results = json.load(f)\n",
    "\n",
    "    best_params_grid = loaded_results['best_params_grid']\n",
    "    best_score_grid = loaded_results['best_score_grid']\n",
    "    test_score = loaded_results['test_score']\n",
    "    best_window_size = loaded_results['best_window_size']\n",
    "\n",
    "    print(f\"Loaded Best Parameters from Grid Search: {best_params_grid}\")\n",
    "    print(f\"Loaded Best Cross-Validation Score from Grid Search: {best_score_grid}\")\n",
    "    print(f\"Loaded Test Set Score: {test_score}\")\n",
    "    print(f\"Loaded Best Window Size: {best_window_size}\")\n",
    "\n",
    "    mfcc_extractor = MFCCFeatureExtractor(\n",
    "        sr=best_params_grid['mfcc__sr'],\n",
    "        n_mfcc=best_params_grid['mfcc__n_mfcc'],\n",
    "        n_fft=best_params_grid['mfcc__n_fft'],\n",
    "        hop_length=best_params_grid['mfcc__hop_length'],\n",
    "        n_mels=best_params_grid['mfcc__n_mels'],\n",
    "        fmin=best_params_grid['mfcc__fmin'],\n",
    "        fmax=best_params_grid['mfcc__fmax']\n",
    "    )\n",
    "\n",
    "    mfcc_features, labels, gender_labels = main(root_dir, best_window_size, mfcc_extractor)\n",
    "\n",
    "    joblib.dump(mfcc_features, 'mfcc_features.joblib')\n",
    "    joblib.dump(labels, 'labels.joblib')\n",
    "    joblib.dump(gender_labels, 'gender_labels.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
